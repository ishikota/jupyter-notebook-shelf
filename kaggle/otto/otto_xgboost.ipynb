{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train  = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape = (61878, 95)\n",
      "['Class_1' 'Class_2' 'Class_3' 'Class_4' 'Class_5' 'Class_6' 'Class_7'\n",
      " 'Class_8' 'Class_9']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count   61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "unique           NaN          NaN           NaN           NaN           NaN   \n",
       "top              NaN          NaN           NaN           NaN           NaN   \n",
       "freq             NaN          NaN           NaN           NaN           NaN   \n",
       "mean    30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std     17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min         1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%     15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%     30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%     46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max     61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "              feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count   61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std         0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "         ...          feat_85       feat_86       feat_87       feat_88  \\\n",
       "count    ...     61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "unique   ...              NaN           NaN           NaN           NaN   \n",
       "top      ...              NaN           NaN           NaN           NaN   \n",
       "freq     ...              NaN           NaN           NaN           NaN   \n",
       "mean     ...         0.532306      1.128576      0.393549      0.874915   \n",
       "std      ...         1.900438      2.681554      1.575455      2.115466   \n",
       "min      ...         0.000000      0.000000      0.000000      0.000000   \n",
       "25%      ...         0.000000      0.000000      0.000000      0.000000   \n",
       "50%      ...         0.000000      0.000000      0.000000      0.000000   \n",
       "75%      ...         0.000000      1.000000      0.000000      1.000000   \n",
       "max      ...        55.000000     65.000000     67.000000     30.000000   \n",
       "\n",
       "             feat_89       feat_90       feat_91       feat_92       feat_93  \\\n",
       "count   61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.457772      0.812421      0.264941      0.380119      0.126135   \n",
       "std         1.527385      4.597804      2.045646      0.982385      1.201720   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        61.000000    130.000000     52.000000     19.000000     87.000000   \n",
       "\n",
       "         target  \n",
       "count     61878  \n",
       "unique        9  \n",
       "top     Class_2  \n",
       "freq      16122  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  \n",
       "\n",
       "[11 rows x 95 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Data shape = (%d, %d)\" % train.shape\n",
    "print train[\"target\"].unique()\n",
    "train.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape = (144368, 94)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "      <td>144368.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>72184.500000</td>\n",
       "      <td>0.386201</td>\n",
       "      <td>0.263597</td>\n",
       "      <td>0.899819</td>\n",
       "      <td>0.780727</td>\n",
       "      <td>0.071498</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.200169</td>\n",
       "      <td>0.667378</td>\n",
       "      <td>1.035271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074989</td>\n",
       "      <td>0.538485</td>\n",
       "      <td>1.128782</td>\n",
       "      <td>0.405249</td>\n",
       "      <td>0.875526</td>\n",
       "      <td>0.473284</td>\n",
       "      <td>0.814010</td>\n",
       "      <td>0.271161</td>\n",
       "      <td>0.388348</td>\n",
       "      <td>0.132675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41675.596169</td>\n",
       "      <td>1.468882</td>\n",
       "      <td>1.261908</td>\n",
       "      <td>2.949106</td>\n",
       "      <td>2.846181</td>\n",
       "      <td>0.428568</td>\n",
       "      <td>0.228354</td>\n",
       "      <td>1.069235</td>\n",
       "      <td>2.286832</td>\n",
       "      <td>3.548618</td>\n",
       "      <td>...</td>\n",
       "      <td>1.288595</td>\n",
       "      <td>1.906121</td>\n",
       "      <td>2.682511</td>\n",
       "      <td>1.631566</td>\n",
       "      <td>2.090288</td>\n",
       "      <td>1.617853</td>\n",
       "      <td>4.603653</td>\n",
       "      <td>2.073627</td>\n",
       "      <td>1.006935</td>\n",
       "      <td>1.302695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36092.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>72184.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>108276.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144368.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id         feat_1         feat_2         feat_3  \\\n",
       "count  144368.000000  144368.000000  144368.000000  144368.000000   \n",
       "mean    72184.500000       0.386201       0.263597       0.899819   \n",
       "std     41675.596169       1.468882       1.261908       2.949106   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%     36092.750000       0.000000       0.000000       0.000000   \n",
       "50%     72184.500000       0.000000       0.000000       0.000000   \n",
       "75%    108276.250000       0.000000       0.000000       0.000000   \n",
       "max    144368.000000      64.000000      45.000000      84.000000   \n",
       "\n",
       "              feat_4         feat_5         feat_6         feat_7  \\\n",
       "count  144368.000000  144368.000000  144368.000000  144368.000000   \n",
       "mean        0.780727       0.071498       0.026439       0.200169   \n",
       "std         2.846181       0.428568       0.228354       1.069235   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        82.000000      14.000000      11.000000      44.000000   \n",
       "\n",
       "              feat_8         feat_9      ...              feat_84  \\\n",
       "count  144368.000000  144368.000000      ...        144368.000000   \n",
       "mean        0.667378       1.035271      ...             0.074989   \n",
       "std         2.286832       3.548618      ...             1.288595   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%         0.000000       0.000000      ...             0.000000   \n",
       "50%         0.000000       0.000000      ...             0.000000   \n",
       "75%         1.000000       0.000000      ...             0.000000   \n",
       "max       100.000000      47.000000      ...           132.000000   \n",
       "\n",
       "             feat_85        feat_86        feat_87        feat_88  \\\n",
       "count  144368.000000  144368.000000  144368.000000  144368.000000   \n",
       "mean        0.538485       1.128782       0.405249       0.875526   \n",
       "std         1.906121       2.682511       1.631566       2.090288   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       1.000000   \n",
       "max        56.000000      73.000000      54.000000      37.000000   \n",
       "\n",
       "             feat_89        feat_90        feat_91        feat_92  \\\n",
       "count  144368.000000  144368.000000  144368.000000  144368.000000   \n",
       "mean        0.473284       0.814010       0.271161       0.388348   \n",
       "std         1.617853       4.603653       2.073627       1.006935   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max        62.000000     119.000000      74.000000      22.000000   \n",
       "\n",
       "             feat_93  \n",
       "count  144368.000000  \n",
       "mean        0.132675  \n",
       "std         1.302695  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        91.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Data shape = (%d, %d)\" % test.shape\n",
    "test.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.array([int(s[-1])-1 for s in train[\"target\"].values])\n",
    "train.drop([\"id\", \"target\"], axis=1, inplace=True)\n",
    "test.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(labels, test_size=0.05, random_state=1234)\n",
    "for train_index, validation_index in sss:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "train_x, train_y = train.values[train_index], labels[train_index]\n",
    "val_x, val_y = train.values[validation_index], labels[validation_index]\n",
    "test_x = test.values\n",
    "xg_train = xgb.DMatrix(train_x, label=train_y)\n",
    "xg_val = xgb.DMatrix(val_x, label=val_y)\n",
    "xg_test = xgb.DMatrix(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model with default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.778664262384\n",
      "RFC Accuracy on validation data = 0.777957336781\n",
      "RFC LogLoss on training data = 0.631658722956\n",
      "RFC LogLoss on validation data = 0.650000060145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(model.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(model.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, model.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, model.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_out_prediction(predict_probability, filename=\"ans.csv\"):\n",
    "    cols = [\"id\"] + [\"Class_%d\"%i for i in range(1,10)]\n",
    "    vals = np.c_[np.arange(start=1, stop=predict_probability.shape[0]+1), predict_probability]\n",
    "    ans = pd.DataFrame(vals, columns=cols, dtype=float)\n",
    "    ans[\"id\"] = ans[\"id\"].astype(int)\n",
    "    ans.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_out_prediction(model.predict_proba(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.64880`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Parameter Tuning\n",
    "- Tune parameter by following [this article](http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1. Fix learning rate and number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 50 rounds.\n",
      "[0]\ttrain-merror:0.320682\teval-merror:0.329670\n",
      "[1]\ttrain-merror:0.266926\teval-merror:0.268261\n",
      "[2]\ttrain-merror:0.254848\teval-merror:0.256626\n",
      "[3]\ttrain-merror:0.244760\teval-merror:0.243697\n",
      "[4]\ttrain-merror:0.239385\teval-merror:0.234971\n",
      "[5]\ttrain-merror:0.233312\teval-merror:0.234324\n",
      "[6]\ttrain-merror:0.229790\teval-merror:0.230123\n",
      "[7]\ttrain-merror:0.226184\teval-merror:0.227537\n",
      "[8]\ttrain-merror:0.221489\teval-merror:0.226891\n",
      "[9]\ttrain-merror:0.218631\teval-merror:0.223659\n",
      "[10]\ttrain-merror:0.216096\teval-merror:0.220427\n",
      "[11]\ttrain-merror:0.213051\teval-merror:0.220103\n",
      "[12]\ttrain-merror:0.210874\teval-merror:0.217195\n",
      "[13]\ttrain-merror:0.208900\teval-merror:0.216871\n",
      "[14]\ttrain-merror:0.206230\teval-merror:0.217518\n",
      "[15]\ttrain-merror:0.204426\teval-merror:0.217518\n",
      "[16]\ttrain-merror:0.203134\teval-merror:0.216225\n",
      "[17]\ttrain-merror:0.200990\teval-merror:0.214286\n",
      "[18]\ttrain-merror:0.199187\teval-merror:0.211054\n",
      "[19]\ttrain-merror:0.197656\teval-merror:0.209114\n",
      "[20]\ttrain-merror:0.195717\teval-merror:0.209438\n",
      "[21]\ttrain-merror:0.194254\teval-merror:0.208145\n",
      "[22]\ttrain-merror:0.192927\teval-merror:0.207498\n",
      "[23]\ttrain-merror:0.191225\teval-merror:0.206206\n",
      "[24]\ttrain-merror:0.189984\teval-merror:0.205236\n",
      "[25]\ttrain-merror:0.188317\teval-merror:0.206852\n",
      "[26]\ttrain-merror:0.187245\teval-merror:0.204913\n",
      "[27]\ttrain-merror:0.185969\teval-merror:0.204266\n",
      "[28]\ttrain-merror:0.184217\teval-merror:0.204913\n",
      "[29]\ttrain-merror:0.182431\teval-merror:0.204590\n",
      "[30]\ttrain-merror:0.180474\teval-merror:0.202650\n",
      "[31]\ttrain-merror:0.178926\teval-merror:0.203297\n",
      "[32]\ttrain-merror:0.177565\teval-merror:0.200711\n",
      "[33]\ttrain-merror:0.176902\teval-merror:0.201034\n",
      "[34]\ttrain-merror:0.175490\teval-merror:0.200711\n",
      "[35]\ttrain-merror:0.174690\teval-merror:0.200388\n",
      "[36]\ttrain-merror:0.172955\teval-merror:0.200388\n",
      "[37]\ttrain-merror:0.171526\teval-merror:0.201034\n",
      "[38]\ttrain-merror:0.170233\teval-merror:0.200065\n",
      "[39]\ttrain-merror:0.169723\teval-merror:0.199741\n",
      "[40]\ttrain-merror:0.167903\teval-merror:0.198449\n",
      "[41]\ttrain-merror:0.166814\teval-merror:0.198125\n",
      "[42]\ttrain-merror:0.166066\teval-merror:0.197802\n",
      "[43]\ttrain-merror:0.165215\teval-merror:0.198125\n",
      "[44]\ttrain-merror:0.164075\teval-merror:0.197156\n",
      "[45]\ttrain-merror:0.163344\teval-merror:0.194570\n",
      "[46]\ttrain-merror:0.162238\teval-merror:0.194893\n",
      "[47]\ttrain-merror:0.161524\teval-merror:0.195540\n",
      "[48]\ttrain-merror:0.160843\teval-merror:0.195217\n",
      "[49]\ttrain-merror:0.160197\teval-merror:0.194893\n",
      "[50]\ttrain-merror:0.159108\teval-merror:0.193277\n",
      "[51]\ttrain-merror:0.158308\teval-merror:0.193601\n",
      "[52]\ttrain-merror:0.157764\teval-merror:0.193277\n",
      "[53]\ttrain-merror:0.156250\teval-merror:0.192308\n",
      "[54]\ttrain-merror:0.155467\teval-merror:0.191661\n",
      "[55]\ttrain-merror:0.154991\teval-merror:0.191984\n",
      "[56]\ttrain-merror:0.154141\teval-merror:0.191338\n",
      "[57]\ttrain-merror:0.152984\teval-merror:0.191015\n",
      "[58]\ttrain-merror:0.152099\teval-merror:0.192308\n",
      "[59]\ttrain-merror:0.151725\teval-merror:0.191661\n",
      "[60]\ttrain-merror:0.150908\teval-merror:0.191984\n",
      "[61]\ttrain-merror:0.150143\teval-merror:0.191338\n",
      "[62]\ttrain-merror:0.149037\teval-merror:0.190692\n",
      "[63]\ttrain-merror:0.148136\teval-merror:0.189722\n",
      "[64]\ttrain-merror:0.147846\teval-merror:0.189722\n",
      "[65]\ttrain-merror:0.147285\teval-merror:0.190692\n",
      "[66]\ttrain-merror:0.146264\teval-merror:0.190368\n",
      "[67]\ttrain-merror:0.144716\teval-merror:0.189722\n",
      "[68]\ttrain-merror:0.144410\teval-merror:0.186813\n",
      "[69]\ttrain-merror:0.143985\teval-merror:0.188752\n",
      "[70]\ttrain-merror:0.143389\teval-merror:0.188106\n",
      "[71]\ttrain-merror:0.142675\teval-merror:0.188106\n",
      "[72]\ttrain-merror:0.142335\teval-merror:0.188106\n",
      "[73]\ttrain-merror:0.141008\teval-merror:0.188106\n",
      "[74]\ttrain-merror:0.140259\teval-merror:0.186813\n",
      "[75]\ttrain-merror:0.139085\teval-merror:0.187136\n",
      "[76]\ttrain-merror:0.138320\teval-merror:0.186490\n",
      "[77]\ttrain-merror:0.137776\teval-merror:0.185844\n",
      "[78]\ttrain-merror:0.136891\teval-merror:0.188106\n",
      "[79]\ttrain-merror:0.136091\teval-merror:0.187136\n",
      "[80]\ttrain-merror:0.135513\teval-merror:0.187460\n",
      "[81]\ttrain-merror:0.134475\teval-merror:0.187460\n",
      "[82]\ttrain-merror:0.134033\teval-merror:0.186167\n",
      "[83]\ttrain-merror:0.133540\teval-merror:0.185520\n",
      "[84]\ttrain-merror:0.132774\teval-merror:0.184228\n",
      "[85]\ttrain-merror:0.132077\teval-merror:0.183904\n",
      "[86]\ttrain-merror:0.130852\teval-merror:0.185844\n",
      "[87]\ttrain-merror:0.130393\teval-merror:0.185844\n",
      "[88]\ttrain-merror:0.129899\teval-merror:0.185520\n",
      "[89]\ttrain-merror:0.129236\teval-merror:0.185197\n",
      "[90]\ttrain-merror:0.128930\teval-merror:0.184228\n",
      "[91]\ttrain-merror:0.128691\teval-merror:0.184551\n",
      "[92]\ttrain-merror:0.128181\teval-merror:0.185520\n",
      "[93]\ttrain-merror:0.127416\teval-merror:0.184874\n",
      "[94]\ttrain-merror:0.127160\teval-merror:0.185197\n",
      "[95]\ttrain-merror:0.126378\teval-merror:0.184874\n",
      "[96]\ttrain-merror:0.125425\teval-merror:0.185197\n",
      "[97]\ttrain-merror:0.124643\teval-merror:0.185197\n",
      "[98]\ttrain-merror:0.123860\teval-merror:0.185844\n",
      "[99]\ttrain-merror:0.123350\teval-merror:0.187460\n",
      "[100]\ttrain-merror:0.122618\teval-merror:0.188106\n",
      "[101]\ttrain-merror:0.122142\teval-merror:0.187783\n",
      "[102]\ttrain-merror:0.121274\teval-merror:0.187136\n",
      "[103]\ttrain-merror:0.120492\teval-merror:0.187460\n",
      "[104]\ttrain-merror:0.120016\teval-merror:0.187783\n",
      "[105]\ttrain-merror:0.119216\teval-merror:0.187460\n",
      "[106]\ttrain-merror:0.118621\teval-merror:0.188429\n",
      "[107]\ttrain-merror:0.117413\teval-merror:0.187460\n",
      "[108]\ttrain-merror:0.116852\teval-merror:0.187460\n",
      "[109]\ttrain-merror:0.116239\teval-merror:0.187460\n",
      "[110]\ttrain-merror:0.115848\teval-merror:0.188106\n",
      "[111]\ttrain-merror:0.115372\teval-merror:0.187136\n",
      "[112]\ttrain-merror:0.115048\teval-merror:0.186167\n",
      "[113]\ttrain-merror:0.114368\teval-merror:0.186490\n",
      "[114]\ttrain-merror:0.114079\teval-merror:0.186167\n",
      "[115]\ttrain-merror:0.113687\teval-merror:0.186490\n",
      "[116]\ttrain-merror:0.113568\teval-merror:0.186167\n",
      "[117]\ttrain-merror:0.113058\teval-merror:0.185520\n",
      "[118]\ttrain-merror:0.112514\teval-merror:0.186167\n",
      "[119]\ttrain-merror:0.112037\teval-merror:0.185197\n",
      "[120]\ttrain-merror:0.111527\teval-merror:0.184874\n",
      "[121]\ttrain-merror:0.111289\teval-merror:0.185197\n",
      "[122]\ttrain-merror:0.110863\teval-merror:0.184228\n",
      "[123]\ttrain-merror:0.110200\teval-merror:0.184551\n",
      "[124]\ttrain-merror:0.109809\teval-merror:0.184874\n",
      "[125]\ttrain-merror:0.109673\teval-merror:0.184874\n",
      "[126]\ttrain-merror:0.109009\teval-merror:0.184874\n",
      "[127]\ttrain-merror:0.108516\teval-merror:0.184551\n",
      "[128]\ttrain-merror:0.107699\teval-merror:0.184228\n",
      "[129]\ttrain-merror:0.107308\teval-merror:0.184228\n",
      "[130]\ttrain-merror:0.107053\teval-merror:0.183904\n",
      "[131]\ttrain-merror:0.106338\teval-merror:0.183581\n",
      "[132]\ttrain-merror:0.106219\teval-merror:0.183581\n",
      "[133]\ttrain-merror:0.105556\teval-merror:0.184228\n",
      "[134]\ttrain-merror:0.104739\teval-merror:0.185844\n",
      "[135]\ttrain-merror:0.104518\teval-merror:0.184228\n",
      "[136]\ttrain-merror:0.103838\teval-merror:0.184551\n",
      "[137]\ttrain-merror:0.103174\teval-merror:0.185197\n",
      "[138]\ttrain-merror:0.102545\teval-merror:0.183904\n",
      "[139]\ttrain-merror:0.102086\teval-merror:0.183258\n",
      "[140]\ttrain-merror:0.101728\teval-merror:0.183904\n",
      "[141]\ttrain-merror:0.101167\teval-merror:0.181965\n",
      "[142]\ttrain-merror:0.100470\teval-merror:0.183581\n",
      "[143]\ttrain-merror:0.099670\teval-merror:0.182612\n",
      "[144]\ttrain-merror:0.099228\teval-merror:0.182612\n",
      "[145]\ttrain-merror:0.098955\teval-merror:0.182612\n",
      "[146]\ttrain-merror:0.098326\teval-merror:0.181642\n",
      "[147]\ttrain-merror:0.098071\teval-merror:0.182935\n",
      "[148]\ttrain-merror:0.097101\teval-merror:0.183258\n",
      "[149]\ttrain-merror:0.096608\teval-merror:0.181642\n",
      "[150]\ttrain-merror:0.096591\teval-merror:0.182288\n",
      "[151]\ttrain-merror:0.096047\teval-merror:0.182612\n",
      "[152]\ttrain-merror:0.095111\teval-merror:0.181965\n",
      "[153]\ttrain-merror:0.094584\teval-merror:0.181642\n",
      "[154]\ttrain-merror:0.093903\teval-merror:0.180349\n",
      "[155]\ttrain-merror:0.093240\teval-merror:0.180672\n",
      "[156]\ttrain-merror:0.092797\teval-merror:0.181965\n",
      "[157]\ttrain-merror:0.092491\teval-merror:0.181319\n",
      "[158]\ttrain-merror:0.092185\teval-merror:0.181642\n",
      "[159]\ttrain-merror:0.091675\teval-merror:0.180672\n",
      "[160]\ttrain-merror:0.091045\teval-merror:0.180672\n",
      "[161]\ttrain-merror:0.090858\teval-merror:0.181965\n",
      "[162]\ttrain-merror:0.090331\teval-merror:0.180349\n",
      "[163]\ttrain-merror:0.089888\teval-merror:0.180995\n",
      "[164]\ttrain-merror:0.089497\teval-merror:0.180026\n",
      "[165]\ttrain-merror:0.088919\teval-merror:0.180026\n",
      "[166]\ttrain-merror:0.088408\teval-merror:0.180026\n",
      "[167]\ttrain-merror:0.088272\teval-merror:0.180026\n",
      "[168]\ttrain-merror:0.087609\teval-merror:0.180349\n",
      "[169]\ttrain-merror:0.087371\teval-merror:0.180026\n",
      "[170]\ttrain-merror:0.087013\teval-merror:0.181319\n",
      "[171]\ttrain-merror:0.086452\teval-merror:0.181319\n",
      "[172]\ttrain-merror:0.085891\teval-merror:0.182288\n",
      "[173]\ttrain-merror:0.085602\teval-merror:0.181319\n",
      "[174]\ttrain-merror:0.085465\teval-merror:0.180349\n",
      "[175]\ttrain-merror:0.084989\teval-merror:0.180349\n",
      "[176]\ttrain-merror:0.084921\teval-merror:0.180672\n",
      "[177]\ttrain-merror:0.084530\teval-merror:0.179703\n",
      "[178]\ttrain-merror:0.084326\teval-merror:0.180995\n",
      "[179]\ttrain-merror:0.083866\teval-merror:0.180672\n",
      "[180]\ttrain-merror:0.083628\teval-merror:0.180026\n",
      "[181]\ttrain-merror:0.083662\teval-merror:0.179056\n",
      "[182]\ttrain-merror:0.083118\teval-merror:0.178733\n",
      "[183]\ttrain-merror:0.083118\teval-merror:0.179703\n",
      "[184]\ttrain-merror:0.082454\teval-merror:0.179379\n",
      "[185]\ttrain-merror:0.082046\teval-merror:0.178087\n",
      "[186]\ttrain-merror:0.081468\teval-merror:0.178410\n",
      "[187]\ttrain-merror:0.081281\teval-merror:0.177763\n",
      "[188]\ttrain-merror:0.080787\teval-merror:0.178087\n",
      "[189]\ttrain-merror:0.080617\teval-merror:0.178733\n",
      "[190]\ttrain-merror:0.080124\teval-merror:0.178733\n",
      "[191]\ttrain-merror:0.079784\teval-merror:0.179056\n",
      "[192]\ttrain-merror:0.079460\teval-merror:0.179703\n",
      "[193]\ttrain-merror:0.079205\teval-merror:0.180349\n",
      "[194]\ttrain-merror:0.078814\teval-merror:0.179056\n",
      "[195]\ttrain-merror:0.078355\teval-merror:0.178410\n",
      "[196]\ttrain-merror:0.078014\teval-merror:0.179056\n",
      "[197]\ttrain-merror:0.077470\teval-merror:0.179379\n",
      "[198]\ttrain-merror:0.077351\teval-merror:0.180349\n",
      "[199]\ttrain-merror:0.077011\teval-merror:0.178733\n",
      "[200]\ttrain-merror:0.076585\teval-merror:0.178733\n",
      "[201]\ttrain-merror:0.076551\teval-merror:0.178087\n",
      "[202]\ttrain-merror:0.076024\teval-merror:0.178733\n",
      "[203]\ttrain-merror:0.075582\teval-merror:0.178087\n",
      "[204]\ttrain-merror:0.075497\teval-merror:0.177763\n",
      "[205]\ttrain-merror:0.074901\teval-merror:0.175824\n",
      "[206]\ttrain-merror:0.074527\teval-merror:0.177117\n",
      "[207]\ttrain-merror:0.074340\teval-merror:0.175501\n",
      "[208]\ttrain-merror:0.074068\teval-merror:0.175824\n",
      "[209]\ttrain-merror:0.073881\teval-merror:0.173885\n",
      "[210]\ttrain-merror:0.073438\teval-merror:0.174208\n",
      "[211]\ttrain-merror:0.073234\teval-merror:0.175501\n",
      "[212]\ttrain-merror:0.072792\teval-merror:0.173885\n",
      "[213]\ttrain-merror:0.072367\teval-merror:0.173885\n",
      "[214]\ttrain-merror:0.072111\teval-merror:0.173885\n",
      "[215]\ttrain-merror:0.071907\teval-merror:0.174855\n",
      "[216]\ttrain-merror:0.071703\teval-merror:0.175501\n",
      "[217]\ttrain-merror:0.071125\teval-merror:0.175824\n",
      "[218]\ttrain-merror:0.070648\teval-merror:0.175178\n",
      "[219]\ttrain-merror:0.070563\teval-merror:0.175824\n",
      "[220]\ttrain-merror:0.070257\teval-merror:0.176471\n",
      "[221]\ttrain-merror:0.069781\teval-merror:0.175824\n",
      "[222]\ttrain-merror:0.069339\teval-merror:0.176147\n",
      "[223]\ttrain-merror:0.069100\teval-merror:0.175824\n",
      "[224]\ttrain-merror:0.068573\teval-merror:0.175178\n",
      "[225]\ttrain-merror:0.068454\teval-merror:0.174531\n",
      "[226]\ttrain-merror:0.068165\teval-merror:0.174208\n",
      "[227]\ttrain-merror:0.068165\teval-merror:0.174208\n",
      "[228]\ttrain-merror:0.067654\teval-merror:0.174208\n",
      "[229]\ttrain-merror:0.067416\teval-merror:0.173885\n",
      "[230]\ttrain-merror:0.067076\teval-merror:0.174208\n",
      "[231]\ttrain-merror:0.066804\teval-merror:0.174208\n",
      "[232]\ttrain-merror:0.066447\teval-merror:0.173885\n",
      "[233]\ttrain-merror:0.065987\teval-merror:0.174208\n",
      "[234]\ttrain-merror:0.065834\teval-merror:0.174531\n",
      "[235]\ttrain-merror:0.065868\teval-merror:0.173562\n",
      "[236]\ttrain-merror:0.065647\teval-merror:0.173885\n",
      "[237]\ttrain-merror:0.065409\teval-merror:0.174208\n",
      "[238]\ttrain-merror:0.065341\teval-merror:0.175178\n",
      "[239]\ttrain-merror:0.065290\teval-merror:0.175501\n",
      "[240]\ttrain-merror:0.064711\teval-merror:0.175824\n",
      "[241]\ttrain-merror:0.064388\teval-merror:0.176147\n",
      "[242]\ttrain-merror:0.064014\teval-merror:0.177117\n",
      "[243]\ttrain-merror:0.063827\teval-merror:0.176471\n",
      "[244]\ttrain-merror:0.063708\teval-merror:0.175178\n",
      "[245]\ttrain-merror:0.063334\teval-merror:0.174531\n",
      "[246]\ttrain-merror:0.062857\teval-merror:0.173885\n",
      "[247]\ttrain-merror:0.062840\teval-merror:0.173885\n",
      "[248]\ttrain-merror:0.062857\teval-merror:0.173562\n",
      "[249]\ttrain-merror:0.062602\teval-merror:0.174208\n",
      "[250]\ttrain-merror:0.062296\teval-merror:0.173885\n",
      "[251]\ttrain-merror:0.062126\teval-merror:0.174531\n",
      "[252]\ttrain-merror:0.061683\teval-merror:0.174855\n",
      "[253]\ttrain-merror:0.061581\teval-merror:0.173562\n",
      "[254]\ttrain-merror:0.061309\teval-merror:0.173562\n",
      "[255]\ttrain-merror:0.061173\teval-merror:0.175178\n",
      "[256]\ttrain-merror:0.060646\teval-merror:0.174531\n",
      "[257]\ttrain-merror:0.060374\teval-merror:0.174855\n",
      "[258]\ttrain-merror:0.060016\teval-merror:0.174531\n",
      "[259]\ttrain-merror:0.059914\teval-merror:0.175178\n",
      "[260]\ttrain-merror:0.059778\teval-merror:0.174855\n",
      "[261]\ttrain-merror:0.059591\teval-merror:0.174855\n",
      "[262]\ttrain-merror:0.059217\teval-merror:0.174531\n",
      "[263]\ttrain-merror:0.058945\teval-merror:0.173885\n",
      "[264]\ttrain-merror:0.058945\teval-merror:0.174208\n",
      "[265]\ttrain-merror:0.058774\teval-merror:0.173562\n",
      "[266]\ttrain-merror:0.058485\teval-merror:0.173239\n",
      "[267]\ttrain-merror:0.058281\teval-merror:0.173885\n",
      "[268]\ttrain-merror:0.058264\teval-merror:0.173239\n",
      "[269]\ttrain-merror:0.058043\teval-merror:0.173885\n",
      "[270]\ttrain-merror:0.057584\teval-merror:0.173562\n",
      "[271]\ttrain-merror:0.057243\teval-merror:0.173239\n",
      "[272]\ttrain-merror:0.057192\teval-merror:0.173885\n",
      "[273]\ttrain-merror:0.056971\teval-merror:0.174531\n",
      "[274]\ttrain-merror:0.056546\teval-merror:0.173239\n",
      "[275]\ttrain-merror:0.056393\teval-merror:0.175501\n",
      "[276]\ttrain-merror:0.056325\teval-merror:0.175178\n",
      "[277]\ttrain-merror:0.056121\teval-merror:0.174855\n",
      "[278]\ttrain-merror:0.055917\teval-merror:0.173885\n",
      "[279]\ttrain-merror:0.055457\teval-merror:0.172592\n",
      "[280]\ttrain-merror:0.055185\teval-merror:0.172269\n",
      "[281]\ttrain-merror:0.055134\teval-merror:0.171622\n",
      "[282]\ttrain-merror:0.054879\teval-merror:0.172269\n",
      "[283]\ttrain-merror:0.054505\teval-merror:0.172915\n",
      "[284]\ttrain-merror:0.054318\teval-merror:0.173885\n",
      "[285]\ttrain-merror:0.054232\teval-merror:0.174208\n",
      "[286]\ttrain-merror:0.054011\teval-merror:0.175178\n",
      "[287]\ttrain-merror:0.053807\teval-merror:0.175178\n",
      "[288]\ttrain-merror:0.053739\teval-merror:0.174855\n",
      "[289]\ttrain-merror:0.053416\teval-merror:0.175501\n",
      "[290]\ttrain-merror:0.053314\teval-merror:0.175178\n",
      "[291]\ttrain-merror:0.053110\teval-merror:0.175178\n",
      "[292]\ttrain-merror:0.052769\teval-merror:0.174531\n",
      "[293]\ttrain-merror:0.052718\teval-merror:0.174208\n",
      "[294]\ttrain-merror:0.052633\teval-merror:0.174208\n",
      "[295]\ttrain-merror:0.052480\teval-merror:0.174531\n",
      "[296]\ttrain-merror:0.052106\teval-merror:0.174531\n",
      "[297]\ttrain-merror:0.051919\teval-merror:0.174208\n",
      "[298]\ttrain-merror:0.051732\teval-merror:0.173239\n",
      "[299]\ttrain-merror:0.051323\teval-merror:0.173562\n",
      "[300]\ttrain-merror:0.051102\teval-merror:0.173885\n",
      "[301]\ttrain-merror:0.050949\teval-merror:0.173562\n",
      "[302]\ttrain-merror:0.050796\teval-merror:0.173239\n",
      "[303]\ttrain-merror:0.050507\teval-merror:0.173562\n",
      "[304]\ttrain-merror:0.050439\teval-merror:0.173562\n",
      "[305]\ttrain-merror:0.050422\teval-merror:0.174208\n",
      "[306]\ttrain-merror:0.049946\teval-merror:0.174208\n",
      "[307]\ttrain-merror:0.050014\teval-merror:0.174208\n",
      "[308]\ttrain-merror:0.050014\teval-merror:0.174208\n",
      "[309]\ttrain-merror:0.049724\teval-merror:0.174208\n",
      "[310]\ttrain-merror:0.049520\teval-merror:0.174855\n",
      "[311]\ttrain-merror:0.049469\teval-merror:0.175501\n",
      "[312]\ttrain-merror:0.049231\teval-merror:0.175501\n",
      "[313]\ttrain-merror:0.049231\teval-merror:0.175501\n",
      "[314]\ttrain-merror:0.048942\teval-merror:0.175501\n",
      "[315]\ttrain-merror:0.048653\teval-merror:0.176147\n",
      "[316]\ttrain-merror:0.048398\teval-merror:0.175178\n",
      "[317]\ttrain-merror:0.048295\teval-merror:0.175501\n",
      "[318]\ttrain-merror:0.048125\teval-merror:0.175824\n",
      "[319]\ttrain-merror:0.048159\teval-merror:0.175501\n",
      "[320]\ttrain-merror:0.048074\teval-merror:0.174208\n",
      "[321]\ttrain-merror:0.047989\teval-merror:0.174855\n",
      "[322]\ttrain-merror:0.047734\teval-merror:0.175178\n",
      "[323]\ttrain-merror:0.047598\teval-merror:0.174531\n",
      "[324]\ttrain-merror:0.047513\teval-merror:0.175501\n",
      "[325]\ttrain-merror:0.047258\teval-merror:0.174855\n",
      "[326]\ttrain-merror:0.047105\teval-merror:0.175178\n",
      "[327]\ttrain-merror:0.046935\teval-merror:0.175824\n",
      "[328]\ttrain-merror:0.046918\teval-merror:0.175501\n",
      "[329]\ttrain-merror:0.046645\teval-merror:0.175501\n",
      "[330]\ttrain-merror:0.046237\teval-merror:0.176147\n",
      "[331]\ttrain-merror:0.046084\teval-merror:0.175824\n",
      "Stopping. Best iteration:\n",
      "[281]\ttrain-merror:0.055134\teval-merror:0.171622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params1 = dict(\n",
    "  learning_rate =0.3,\n",
    "  max_depth=5,\n",
    "  min_child_weight=1,\n",
    "  gamma=0,\n",
    "  subsample=0.8,\n",
    "  colsample_bytree=0.8,\n",
    "  objective= 'multi:softprob',\n",
    "  scale_pos_weight=1,\n",
    "  seed=27,\n",
    "  num_class=9\n",
    ")\n",
    "watchlist = [(xg_train, 'train'),(xg_val, 'eval')]\n",
    "xgb1 = xgb.train(xgb_params1, xg_train, num_boost_round=1000,evals=watchlist,early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC LogLoss on training data = 0.162447127248\n",
      "RFC LogLoss on validation data = 0.490620955496\n"
     ]
    }
   ],
   "source": [
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, xgb1.predict(xg_train)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, xgb1.predict(xg_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed below parameters\n",
    "```py\n",
    "parameters = {\n",
    "        'learning rate' : 0.3\n",
    "        'n_estimators' : 281\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_out_prediction(xgb1.predict(xg_test), filename=\"xgb1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.47626`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2. Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-23 11:13:20.757867\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=1 - 2.6min\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=1 - 2.3min\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=1 - 2.3min\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=3 - 2.3min\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=3 - 2.2min\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=3 - 2.3min\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=5 - 2.4min\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=5 - 2.4min\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=3, min_child_weight=5 - 2.4min\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=1 - 4.0min\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=1 - 3.0min\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=1 - 2.9min\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=3 - 2.8min\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=3 - 2.7min\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=3 - 2.7min\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=5 - 2.8min\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=5 - 2.8min\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=5, min_child_weight=5 - 2.7min\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=1 - 4.2min\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=1 - 3.9min\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=1 - 4.1min\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=3 - 4.0min\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=3 - 4.1min\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=3 - 4.2min\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=5 - 4.5min\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=5 - 4.3min\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=7, min_child_weight=5 - 4.2min\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=1 - 5.5min\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=1 - 5.7min\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=1 - 5.6min\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=3 - 5.3min\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=3 - 5.2min\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=3 - 5.6min\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=5 - 5.4min\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=5 - 5.4min\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV] ........................ max_depth=9, min_child_weight=5 - 5.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 134.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-23 13:32:04.198070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "grid_param1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "xgb2 = XGBClassifier(\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb2, param_grid = grid_param1, scoring='log_loss', verbose=2)\n",
    "gsearch1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.917426510615\n",
      "RFC Accuracy on validation data = 0.824499030381\n",
      "RFC LogLoss on training data = 0.249947829689\n",
      "RFC LogLoss on validation data = 0.478891561661\n"
     ]
    }
   ],
   "source": [
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(gsearch1.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(gsearch1.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, gsearch1.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, gsearch1.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed below parameters\n",
    "```py\n",
    "parameters = {\n",
    "        'learning rate' : 0.3,\n",
    "        'n_estimators' : 281,\n",
    "        'max_depth': 5,\n",
    "        'min_child_weight': 5\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3. Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .............................................. gamma=0.0 - 3.1min\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .............................................. gamma=0.0 - 3.0min\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .............................................. gamma=0.0 - 3.0min\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .............................................. gamma=0.1 - 3.0min\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .............................................. gamma=0.1 - 3.0min\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .............................................. gamma=0.1 - 3.0min\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............................................. gamma=0.2 - 3.0min\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............................................. gamma=0.2 - 3.0min\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............................................. gamma=0.2 - 3.3min\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............................................. gamma=0.3 - 3.4min\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............................................. gamma=0.3 - 3.1min\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............................................. gamma=0.3 - 3.1min\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............................................. gamma=0.4 - 3.0min\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............................................. gamma=0.4 - 3.0min\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............................................. gamma=0.4 - 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, missing=None, n_estimators=281, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=2)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param2 = {\n",
    "    'gamma' : [i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "xgb3 = XGBClassifier(\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = xgb3, param_grid = grid_param2, scoring='log_loss', verbose=2)\n",
    "gsearch2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.0}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.917426510615\n",
      "RFC Accuracy on validation data = 0.824499030381\n",
      "RFC LogLoss on training data = 0.249947829689\n",
      "RFC LogLoss on validation data = 0.478891561661\n"
     ]
    }
   ],
   "source": [
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(gsearch2.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(gsearch2.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, gsearch2.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, gsearch2.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.6 - 1.8min\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.6 - 1.9min\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.6 - 1.9min\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.6 - 1.9min\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.6 - 1.8min\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.6 - 1.7min\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.6 - 1.7min\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.6 - 1.8min\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.7 - 2.2min\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.7 - 2.0min\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.7 - 2.2min\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.7 - 2.2min\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.7 - 2.1min\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.7 - 2.1min\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.7 - 2.0min\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.7 - 1.9min\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.8 - 2.6min\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.8 - 2.6min\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.8 - 2.6min\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.8 - 2.5min\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.8 - 2.5min\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.8 - 2.5min\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.8 - 2.5min\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.8 - 2.6min\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.9 - 2.9min\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.6, colsample_bytree=0.9 - 3.5min\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.9 - 3.5min\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.7, colsample_bytree=0.9 - 3.2min\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.9 - 3.1min\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.8, colsample_bytree=0.9 - 2.6min\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.9 - 2.5min\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.9 - 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 75.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0, learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, missing=None, n_estimators=281, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=2)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param3 = {\n",
    "    'subsample' : [i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree' : [i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "xgb4 = XGBClassifier(\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    gamma= 0.0,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = xgb4, param_grid = grid_param3, scoring='log_loss', verbose=2, cv=2)\n",
    "gsearch3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6, 'subsample': 0.9}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.910996189439\n",
      "RFC Accuracy on validation data = 0.819974143504\n",
      "RFC LogLoss on training data = 0.264219604586\n",
      "RFC LogLoss on validation data = 0.489091737011\n"
     ]
    }
   ],
   "source": [
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(gsearch3.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(gsearch3.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, gsearch3.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, gsearch3.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] subsample=0.9, colsample_bytree=0.4 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.4 - 1.6min\n",
      "[CV] subsample=0.9, colsample_bytree=0.4 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.4 - 1.5min\n",
      "[CV] subsample=0.95, colsample_bytree=0.4 ............................\n",
      "[CV] ................... subsample=0.95, colsample_bytree=0.4 - 1.5min\n",
      "[CV] subsample=0.95, colsample_bytree=0.4 ............................\n",
      "[CV] ................... subsample=0.95, colsample_bytree=0.4 - 1.6min\n",
      "[CV] subsample=0.9, colsample_bytree=0.5 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.5 - 2.4min\n",
      "[CV] subsample=0.9, colsample_bytree=0.5 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.5 - 2.0min\n",
      "[CV] subsample=0.95, colsample_bytree=0.5 ............................\n",
      "[CV] ................... subsample=0.95, colsample_bytree=0.5 - 1.7min\n",
      "[CV] subsample=0.95, colsample_bytree=0.5 ............................\n",
      "[CV] ................... subsample=0.95, colsample_bytree=0.5 - 1.6min\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.6 - 1.8min\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV] .................... subsample=0.9, colsample_bytree=0.6 - 2.0min\n",
      "[CV] subsample=0.95, colsample_bytree=0.6 ............................\n",
      "[CV] ................... subsample=0.95, colsample_bytree=0.6 - 1.9min\n",
      "[CV] subsample=0.95, colsample_bytree=0.6 ............................\n",
      "[CV] ................... subsample=0.95, colsample_bytree=0.6 - 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 21.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0, learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, missing=None, n_estimators=281, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.9, 0.95], 'colsample_bytree': [0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=2)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param4 = {\n",
    "    'colsample_bytree': [0.4, 0.5, 0.6]\n",
    "    'subsample' : [0.9, 0.95]\n",
    "}\n",
    "\n",
    "xgb4 = XGBClassifier(\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    gamma= 0.0,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator = xgb4, param_grid = grid_param4, scoring='log_loss', verbose=2, cv=2)\n",
    "gsearch4.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5, 'subsample': 0.95}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] subsample=0.95 ..................................................\n",
      "[CV] ......................................... subsample=0.95 - 1.7min\n",
      "[CV] subsample=0.95 ..................................................\n",
      "[CV] ......................................... subsample=0.95 - 1.7min\n",
      "[CV] subsample=0.97 ..................................................\n",
      "[CV] ......................................... subsample=0.97 - 2.0min\n",
      "[CV] subsample=0.97 ..................................................\n",
      "[CV] ......................................... subsample=0.97 - 1.6min\n",
      "[CV] subsample=0.99 ..................................................\n",
      "[CV] ......................................... subsample=0.99 - 1.5min\n",
      "[CV] subsample=0.99 ..................................................\n",
      "[CV] ......................................... subsample=0.99 - 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0.0, learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, missing=None, n_estimators=281, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.95, 0.97, 0.99]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param5 = {\n",
    "    'subsample' : [0.95, 0.97, 0.99]\n",
    "}\n",
    "\n",
    "xgb4 = XGBClassifier(\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    gamma= 0.0,\n",
    "    colsample_bytree = 0.5,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator = xgb4, param_grid = grid_param5, scoring='log_loss', verbose=2, cv=2)\n",
    "gsearch5.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.99}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.904650925422\n",
      "RFC Accuracy on validation data = 0.828377504848\n",
      "RFC LogLoss on training data = 0.280739947687\n",
      "RFC LogLoss on validation data = 0.479212884054\n"
     ]
    }
   ],
   "source": [
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(gsearch5.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(gsearch5.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, gsearch5.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, gsearch5.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed below parameters\n",
    "```py\n",
    "parameters = {\n",
    "        'learning rate' : 0.3,\n",
    "        'n_estimators' : 281,\n",
    "        'max_depth': 5,\n",
    "        'min_child_weight': 5,\n",
    "        'gamma': 0.0,\n",
    "        'colsample_bytree': 0.6, \n",
    "        'subsample': 0.9\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] ........................................ reg_alpha=1e-05 - 1.5min\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] ........................................ reg_alpha=1e-05 - 1.7min\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ......................................... reg_alpha=0.01 - 1.8min\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ......................................... reg_alpha=0.01 - 1.6min\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .......................................... reg_alpha=0.1 - 1.5min\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .......................................... reg_alpha=0.1 - 1.6min\n",
      "[CV] reg_alpha=1 .....................................................\n",
      "[CV] ............................................ reg_alpha=1 - 1.6min\n",
      "[CV] reg_alpha=1 .....................................................\n",
      "[CV] ............................................ reg_alpha=1 - 1.7min\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] .......................................... reg_alpha=100 -  43.5s\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] .......................................... reg_alpha=100 -  42.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0.0, learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, missing=None, n_estimators=281, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.99),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=2)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param6 = {\n",
    "   'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "xgb5 = XGBClassifier(\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    gamma= 0.0,\n",
    "    colsample_bytree=0.5, \n",
    "    subsample=0.99,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch6 = GridSearchCV(estimator = xgb5, param_grid = grid_param6, scoring='log_loss', verbose=2, cv=2)\n",
    "gsearch6.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 1}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.909669297768\n",
      "RFC Accuracy on validation data = 0.825791855204\n",
      "RFC LogLoss on training data = 0.27363384561\n",
      "RFC LogLoss on validation data = 0.472169675172\n"
     ]
    }
   ],
   "source": [
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(gsearch6.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(gsearch6.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, gsearch6.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, gsearch6.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] learning_rate=0.1 ...............................................\n",
      "[CV] ...................................... learning_rate=0.1 - 1.5min\n",
      "[CV] learning_rate=0.1 ...............................................\n",
      "[CV] ...................................... learning_rate=0.1 - 1.6min\n",
      "[CV] learning_rate=0.2 ...............................................\n",
      "[CV] ...................................... learning_rate=0.2 - 1.6min\n",
      "[CV] learning_rate=0.2 ...............................................\n",
      "[CV] ...................................... learning_rate=0.2 - 1.9min\n",
      "[CV] learning_rate=0.3 ...............................................\n",
      "[CV] ...................................... learning_rate=0.3 - 1.6min\n",
      "[CV] learning_rate=0.3 ...............................................\n",
      "[CV] ...................................... learning_rate=0.3 - 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0.0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=5, missing=None, n_estimators=281, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=1, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.99),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.1, 0.2, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=2)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param7 = {\n",
    "   'learning_rate' : [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "xgb6 = XGBClassifier(\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    gamma= 0.0,\n",
    "    colsample_bytree=0.5, \n",
    "    subsample=0.99,\n",
    "    reg_alpha=1,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "gsearch7 = GridSearchCV(estimator = xgb6, param_grid = grid_param7, scoring='log_loss', verbose=2, cv=2)\n",
    "gsearch7.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy on training data = 0.884866630376\n",
      "RFC Accuracy on validation data = 0.823529411765\n",
      "RFC LogLoss on training data = 0.330114740615\n",
      "RFC LogLoss on validation data = 0.483641115366\n"
     ]
    }
   ],
   "source": [
    "print 'RFC Accuracy on training data = {score}'.format(score=accuracy_score(gsearch7.predict(train_x), train_y))\n",
    "print 'RFC Accuracy on validation data = {score}'.format(score=accuracy_score(gsearch7.predict(val_x), val_y))\n",
    "print 'RFC LogLoss on training data = {score}'.format(score=log_loss(train_y, gsearch7.predict_proba(train_x)))\n",
    "print 'RFC LogLoss on validation data = {score}'.format(score=log_loss(val_y, gsearch7.predict_proba(val_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and LogLoss get worse... why?  \n",
    "So we do use `gsearch6` as best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt below parameter\n",
    "```py\n",
    "tuned_params = {\n",
    "    learning_rate =0.3,\n",
    "    n_estimators = 281,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 5,\n",
    "    gamma= 0.0,\n",
    "    colsample_bytree=0.5, \n",
    "    subsample=0.99,\n",
    "    reg_alpha=1,\n",
    "    objective= 'multi:softprob',\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_out_prediction(gsearch6.predict_proba(test_x), filename=\"tuned_xgb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.46485`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "def save_model(model, name):\n",
    "    os.system(\"mkdir -p %s_pickel\" % name)\n",
    "    fpath = os.path.join(\"%s_pickel\" % name, \"%s.pkl\" % name)\n",
    "    joblib.dump(model, fpath)\n",
    "    \n",
    "save_model(gsearch6, name=type(gsearch6.estimator).__name__.lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Create a new model by **emsenbling 3 models of prediction** with optimized weight.  \n",
    "We use these models to create a new model. (training of these models are already done)\n",
    "1. RandomForestClassifier (library: sklearn)\n",
    "2. XGBoostClassifier (library: dmlc/xgboost)\n",
    "3. NeuralNetwork (library: keras)\n",
    "\n",
    "(reference : https://www.kaggle.com/hsperr/otto-group-product-classification-challenge/finding-ensamble-weights )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "We create a new model by following steps\n",
    "1. Load 3 models.\n",
    "2. Find best weight by optimization method\n",
    "  - We use *Nelder-Mead* method in weight optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "def print_model_performance(model, train_x, train_y, val_x, val_y):\n",
    "    print 'Accuracy on training data = {score}'.format(score=accuracy_score(model.predict(train_x), train_y))\n",
    "    print 'Accuracy on validation data = {score}'.format(score=accuracy_score(model.predict(val_x), val_y))\n",
    "    print 'LogLoss on training data = {score}'.format(score=log_loss(train_y, model.predict_proba(train_x)))\n",
    "    print 'LogLoss on validation data = {score}'.format(score=log_loss(val_y, model.predict_proba(val_x)))\n",
    "    \n",
    "def save_model(model, name):\n",
    "    os.system(\"mkdir -p %s_pickel\" % name)\n",
    "    fpath = os.path.join(\"%s_pickel\" % name, \"%s.pkl\" % name)\n",
    "    joblib.dump(model, fpath)\n",
    "\n",
    "def load_model(name):\n",
    "    fpath = os.path.join(\"%s_pickel\" % name, \"%s.pkl\" % name)\n",
    "    return joblib.load(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import xgboost as xgb\n",
    "\n",
    "train  = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "labels = np.array([int(s[-1])-1 for s in train[\"target\"].values])\n",
    "train.drop([\"id\", \"target\"], axis=1, inplace=True)\n",
    "test.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(labels, test_size=0.05, random_state=1234)\n",
    "for train_index, validation_index in sss:\n",
    "    break\n",
    "\n",
    "train_x, train_y = train.values[train_index], labels[train_index]\n",
    "val_x, val_y = train.values[validation_index], labels[validation_index]\n",
    "test_x = test.values\n",
    "xg_train = xgb.DMatrix(train_x, label=train_y)\n",
    "xg_val = xgb.DMatrix(val_x, label=val_y)\n",
    "xg_test = xgb.DMatrix(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.974840092542\n",
      "Accuracy on validation data = 0.815772462831\n",
      "LogLoss on training data = 0.212241486064\n",
      "LogLoss on validation data = 0.539763757571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = GridSearchCV(RandomForestClassifier(), {}, scoring=\"log_loss\")\n",
    "rfc = load_model(type(rfc.estimator).__name__.lower())\n",
    "print_model_performance(rfc, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.909669297768\n",
      "Accuracy on validation data = 0.825791855204\n",
      "LogLoss on training data = 0.27363384561\n",
      "LogLoss on validation data = 0.472169675172\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "bst = GridSearchCV(XGBClassifier(), {}, scoring=\"log_loss\")\n",
    "bst = load_model(type(bst.estimator).__name__.lower())\n",
    "print_model_performance(bst, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find best weight by optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Define objective function to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def objective_func(weights, models, X, y):\n",
    "    weighted_pred = np.array([w*model.predict_proba(X) for w, model in zip(weights, models)]).sum(axis=0)\n",
    "    return log_loss(y, weighted_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Define function to generate initial value of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def gen_initial_guess(model_num):\n",
    "    rand_nums = [random.random() for _ in range(model_num)]\n",
    "    return [num/sum(rand_nums) for num in rand_nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3  Define weight constraints (sum of weights is 1 and weight range is [0,1])\n",
    "- `{ type = \"eq\", ... }` means\n",
    "> Equality constraint means that the constraint function result is to be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const = { \"type\" : \"eq\", \"fun\" : lambda weights: 1-sum(weights) }\n",
    "bounds = [(0,1)] * len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 Find best weight by running optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.466738680621\n",
      "Best Weights: [ 0.13204818  0.86795182]\n"
     ]
    }
   ],
   "source": [
    "models = [rfc, bst]\n",
    "minimize_curry = lambda init_state: minimize(objective_func, init_state, method='SLSQP', bounds=bounds, constraints=const, args=(models, val_x, val_y))\n",
    "results = [minimize_curry(gen_initial_guess(len(models))) for _ in range(10)]\n",
    "best = sorted(results, key=lambda res: res[\"fun\"])[-1]\n",
    "print('Best Score: {best_score}'.format(best_score=best['fun']))\n",
    "print('Best Weights: {best_weights}'.format(best_weights=best['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmsembledModel:\n",
    "    \n",
    "    def __init__(self, models, weights):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        weighted_prediction = np.array([w*model.predict(X) for w, model in zip(self.weights, self.models)]).sum(axis=0)\n",
    "        return [round(n) for n in weighted_prediction]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.array([w*model.predict_proba(X) for w, model in zip(self.weights, self.models)]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.908988840501\n",
      "Accuracy on validation data = 0.821913380737\n",
      "LogLoss on training data = 0.257721155409\n",
      "LogLoss on validation data = 0.466738680621\n"
     ]
    }
   ],
   "source": [
    "emsemble_clf = EmsembledModel(models, best['x'])\n",
    "print_model_performance(emsemble_clf, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_out_prediction(predict_probability, filename=\"ans.csv\"):\n",
    "    cols = [\"id\"] + [\"Class_%d\"%i for i in range(1,10)]\n",
    "    vals = np.c_[np.arange(start=1, stop=predict_probability.shape[0]+1), predict_probability]\n",
    "    ans = pd.DataFrame(vals, columns=cols, dtype=float)\n",
    "    ans[\"id\"] = ans[\"id\"].astype(int)\n",
    "    ans.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_out_prediction(emsemble_clf.predict_proba(test_x), \"emsemble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.46091`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Create a new model by **emsenbling 3 models of prediction** with optimized weight.  \n",
    "We use these models to create a new model. (training of these models are already done)\n",
    "1. RandomForestClassifier (library: sklearn)\n",
    "2. XGBoostClassifier (library: dmlc/xgboost)\n",
    "3. NeuralNetwork (library: keras)\n",
    "\n",
    "(reference : https://www.kaggle.com/hsperr/otto-group-product-classification-challenge/finding-ensamble-weights )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "We create a new model by following steps\n",
    "1. Load 3 models.\n",
    "2. Find best weight by optimization method\n",
    "  - We use *SLSQP* method in weight optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "def print_model_performance(model, train_x, train_y, val_x, val_y):\n",
    "    print 'Accuracy on training data = {score}'.format(score=accuracy_score(model.predict(train_x), train_y))\n",
    "    print 'Accuracy on validation data = {score}'.format(score=accuracy_score(model.predict(val_x), val_y))\n",
    "    print 'LogLoss on training data = {score}'.format(score=log_loss(train_y, model.predict_proba(train_x)))\n",
    "    print 'LogLoss on validation data = {score}'.format(score=log_loss(val_y, model.predict_proba(val_x)))\n",
    "    \n",
    "def save_model(model, name):\n",
    "    os.system(\"mkdir -p %s_pickel\" % name)\n",
    "    fpath = os.path.join(\"%s_pickel\" % name, \"%s.pkl\" % name)\n",
    "    joblib.dump(model, fpath)\n",
    "\n",
    "def load_model(name):\n",
    "    fpath = os.path.join(\"%s_pickel\" % name, \"%s.pkl\" % name)\n",
    "    return joblib.load(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import xgboost as xgb\n",
    "\n",
    "train  = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "labels = np.array([int(s[-1])-1 for s in train[\"target\"].values])\n",
    "train.drop([\"id\", \"target\"], axis=1, inplace=True)\n",
    "test.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "def normalize(_df, colname):\n",
    "    df = _df[:]  # Deepcopy here\n",
    "    df[colname] = (df[colname] - df[colname].mean()) / df[colname].std()\n",
    "    return df\n",
    "\n",
    "train_normalize = train[:]\n",
    "for colname in train.columns.values.tolist():\n",
    "    train_normalize = normalize(train_normalize, colname)\n",
    "\n",
    "test_normalize = test[:]\n",
    "for colname in test.columns.values.tolist():\n",
    "    test_normalize = normalize(test_normalize, colname)\n",
    "\n",
    "sss = StratifiedShuffleSplit(labels, test_size=0.05, random_state=1234)\n",
    "for train_index, validation_index in sss:\n",
    "    break\n",
    "\n",
    "train_x, train_y = train.values[train_index], labels[train_index]\n",
    "val_x, val_y = train.values[validation_index], labels[validation_index]\n",
    "train_normx, val_normx  = train_normalize.values[train_index], train_normalize.values[validation_index]\n",
    "test_x, test_normx = test.values, test_normalize.values\n",
    "train_Y, val_Y = [np_utils.to_categorical(y, 9) for y in [train_y, val_y]]\n",
    "xg_train = xgb.DMatrix(train_x, label=train_y)\n",
    "xg_val = xgb.DMatrix(val_x, label=val_y)\n",
    "xg_test = xgb.DMatrix(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.974840092542\n",
      "Accuracy on validation data = 0.815772462831\n",
      "LogLoss on training data = 0.212241486064\n",
      "LogLoss on validation data = 0.539763757571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = GridSearchCV(RandomForestClassifier(), {}, scoring=\"log_loss\")\n",
    "rfc = load_model(type(rfc.estimator).__name__.lower())\n",
    "print_model_performance(rfc, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.54715 (rank = 1777)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.909669297768\n",
      "Accuracy on validation data = 0.825791855204\n",
      "LogLoss on training data = 0.27363384561\n",
      "LogLoss on validation data = 0.472169675172\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "bst = GridSearchCV(XGBClassifier(), {}, scoring=\"log_loss\")\n",
    "bst = load_model(type(bst.estimator).__name__.lower())\n",
    "print_model_performance(bst, train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.46485 (rank = 962)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create wrapper class to match interface with sklearn's classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetClassifier:\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.__name__ = \"NeuralNetClassifier\"\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X), axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.854603293413\n",
      "Accuracy on validation data = 0.814479638009\n",
      "LogLoss on training data = 0.367944563155\n",
      "LogLoss on validation data = 0.492036984512\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.15, input_shape=(93,)))\n",
    "model.add(Dense(1024, W_constraint=maxnorm(4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, W_constraint=maxnorm(4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",  optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.load_weights(\"otto_nn_weights.h5\")\n",
    "nn = NeuralNetClassifier(model)\n",
    "print_model_performance(nn, train_normx, train_y, val_normx, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is  0.48590 (rank = 1220)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find best weight by optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Define objective function to optimize\n",
    "- input of neural net should be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "is_nn = lambda model: isinstance(model , NeuralNetClassifier)\n",
    "def objective_func(weights, models, X, normX, y):\n",
    "    weighted_pred = np.array(\n",
    "        [w*model.predict_proba(normX if is_nn(model) else X) for w, model in zip(weights, models)]\n",
    "    ).sum(axis=0)\n",
    "    return log_loss(y, weighted_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Define function to generate initial value of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def gen_initial_guess(model_num):\n",
    "    rand_nums = [random.random() for _ in range(model_num)]\n",
    "    return [num/sum(rand_nums) for num in rand_nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3  Define weight constraints (sum of weights is 1 and weight range is [0,1])\n",
    "- `{ type = \"eq\", ... }` means\n",
    "> Equality constraint means that the constraint function result is to be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const = { \"type\" : \"eq\", \"fun\" : lambda weights: 1-sum(weights) }\n",
    "bounds = [(0,1)] * len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 Find best weight by running optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.466738680621\n",
      "Best Weights: [ 0.13204818  0.86795182]\n"
     ]
    }
   ],
   "source": [
    "models = [rfc, bst]\n",
    "minimize_curry = lambda init_state: minimize(objective_func, init_state, method='SLSQP', bounds=bounds, constraints=const, args=(models, val_x, val_y))\n",
    "results = [minimize_curry(gen_initial_guess(len(models))) for _ in range(1)]\n",
    "best = sorted(results, key=lambda res: res[\"fun\"])[-1]\n",
    "print('Best Score: {best_score}'.format(best_score=best['fun']))\n",
    "print('Best Weights: {best_weights}'.format(best_weights=best['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForest and XGBoost and NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.453937420176\n",
      "Best Weights: [ 0.03732232  0.57860947  0.38406821]\n"
     ]
    }
   ],
   "source": [
    "models = [rfc, bst, nn]\n",
    "minimize_curry = lambda init_state: minimize(objective_func, init_state, method='SLSQP', bounds=bounds, constraints=const, args=(models, val_x, val_normx, val_y))\n",
    "results = [minimize_curry(gen_initial_guess(len(models))) for _ in range(10)]\n",
    "best = sorted(results, key=lambda res: res[\"fun\"])[-1]\n",
    "print('Best Score: {best_score}'.format(best_score=best['fun']))\n",
    "print('Best Weights: {best_weights}'.format(best_weights=best['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmsembledModel:\n",
    "    \n",
    "    def __init__(self, models, weights):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "        \n",
    "    def predict(self, X, normX):\n",
    "        weighted_prediction = np.array([w*self.__predict(model, X, normX) for w, model in zip(self.weights, self.models)]).sum(axis=0)\n",
    "        return [round(n) for n in weighted_prediction]\n",
    "    \n",
    "    def predict_proba(self, X, normX):\n",
    "        return np.array([w*self.__predict_proba(model, X, normX) for w, model in zip(self.weights, self.models)]).sum(axis=0)\n",
    "        \n",
    "    def __predict(self, model, X, normX):\n",
    "        return model.predict(normX if self.__is_nn(model) else X)\n",
    "    \n",
    "    def __predict_proba(self, model, X, normX):\n",
    "        return model.predict_proba(normX if self.__is_nn(model) else X)\n",
    "\n",
    "    def __is_nn(self, model):\n",
    "        return isinstance(model , NeuralNetClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Emsemble RandomForest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.908988840501\n",
      "Accuracy on validation data = 0.821913380737\n",
      "LogLoss on training data = 0.257721155409\n",
      "LogLoss on validation data = 0.466738680621\n"
     ]
    }
   ],
   "source": [
    "emsemble_clf = EmsembledModel(models, best['x'])\n",
    "print 'Accuracy on training data = {score}'.format(score=accuracy_score(emsemble_clf.predict(train_x, train_normx), train_y))\n",
    "print 'Accuracy on validation data = {score}'.format(score=accuracy_score(emsemble_clf.predict(val_x, val_normx), val_y))\n",
    "print 'LogLoss on training data = {score}'.format(score=log_loss(train_y, emsemble_clf.predict_proba(train_x, train_normx)))\n",
    "print 'LogLoss on validation data = {score}'.format(score=log_loss(val_y, emsemble_clf.predict_proba(val_x, val_normx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_out_prediction(predict_probability, filename=\"ans.csv\"):\n",
    "    cols = [\"id\"] + [\"Class_%d\"%i for i in range(1,10)]\n",
    "    vals = np.c_[np.arange(start=1, stop=predict_probability.shape[0]+1), predict_probability]\n",
    "    ans = pd.DataFrame(vals, columns=cols, dtype=float)\n",
    "    ans[\"id\"] = ans[\"id\"].astype(int)\n",
    "    ans.to_csv(filename, index=False)\n",
    "\n",
    "write_out_prediction(emsemble_clf.predict_proba(test_x, test_normx), \"emsemble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.46091 (rank = 905)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Emsemble RandomForest and XGBoost and NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.884662493195\n",
      "Accuracy on validation data = 0.811247575953\n",
      "LogLoss on training data = 0.288268528991\n",
      "LogLoss on validation data = 0.453937420176\n"
     ]
    }
   ],
   "source": [
    "emsemble_clf = EmsembledModel(models, best['x'])\n",
    "print 'Accuracy on training data = {score}'.format(score=accuracy_score(emsemble_clf.predict(train_x, train_normx), train_y))\n",
    "print 'Accuracy on validation data = {score}'.format(score=accuracy_score(emsemble_clf.predict(val_x, val_normx), val_y))\n",
    "print 'LogLoss on training data = {score}'.format(score=log_loss(train_y, emsemble_clf.predict_proba(train_x, train_normx)))\n",
    "print 'LogLoss on validation data = {score}'.format(score=log_loss(val_y, emsemble_clf.predict_proba(val_x, val_normx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_out_prediction(emsemble_clf.predict_proba(test_x, test_normx), \"emsemble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>> score is 0.44720 (rank = 633) \n",
    "        best weight is { \"rfc\": 0.03107124, \"xgb\": 0.58161524,  \"nn\": 0.38731352 }`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
